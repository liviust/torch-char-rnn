{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lil' Scrapy: Building a Rap Lyric Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build List of Lyrics URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's collect a list of URLs to scrape. I've chosen [ohhla.com](http://www.ohhla.com) since the lyrics are all pretty centrally located, are stored in .txt format, and don't contain much overhead or javascript to work past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all the lyrics are contained in 5 subsets of the main index page\n",
    "\n",
    "root_urls = [\"http://ohhla.com/all.html\", \"http://ohhla.com/all_two.html\", \"http://ohhla.com/all_three.html\",\n",
    "             \"http://ohhla.com/all_four.html\", \"http://ohhla.com/all_five.html\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we iterate through the 5 subsets, grab any URLs that don't have \"anonymous\" in the name (since these are more complicated to scrape and seem to be associated with lesser-known artists), and then append them to a URL master\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "for root in root_urls:\n",
    "    index_page = requests.get(root).content\n",
    "    soup = BeautifulSoup(index_page, \"lxml\")\n",
    "    filtered_soup = soup.find(\"pre\")\n",
    "    links = filtered_soup.find_all(\"a\")\n",
    "    for link in links:\n",
    "        try:\n",
    "            url = link['href']\n",
    "            if \"anonymous\" not in url:\n",
    "                urls.append(url)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total URLs found: 141\n",
      "\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['YFA_snoopdogg_two.html',\n",
       " 'YFA_BOB.html',\n",
       " 'YFA_mop.html',\n",
       " 'YFA_peterock.html',\n",
       " 'YFA_nappy.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = list(set(urls))\n",
    "\n",
    "print(\"Total URLs found:\", len(urls))\n",
    "print(\"\\nSamples:\")\n",
    "urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move into actually parsing the lyrics and writing them to file, let's make sure we can do some basic cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample lyrics\n",
    "\n",
    "s = \"\"\"\n",
    "Artist: Da Brat\n",
    "Album:  Funkafied\n",
    "Song:   Da Shit Ya Can't Fuc Wit\n",
    "Typed by: lyric724@aol.com\n",
    "\n",
    "I promise the funk the whole funk and nothin' but the funk...Yoooooohoo\n",
    "\n",
    "Chorus: I be Da B-R-A-T the new lady wit dat shit ya can't fuck wit (say 2x)\n",
    "\n",
    "Verse 1:\n",
    "\n",
    "Uh, fool sittin' all fat brat tat tat tat (bitch and its like that)\n",
    "Well let me lift you to the sky\n",
    "Just climb aboard the B-R-A-T ride\n",
    "Those with no love I stay about like GOD\n",
    "Quick to pull ya trigga nigga quick to pull ya card\n",
    "And it don't stop and it don't quit\n",
    "In ninety-fo I be the sho shot shit\n",
    "And in years to come shit ain't gonna change\n",
    "Sosodef, you know the name of the game\n",
    "And those that say they don't, nigga bitch please\n",
    "Cuz, we be known for makin' dem Geeees\n",
    "Settin them swole, steady going gold\n",
    "Whateva we release, whateva we unfold\n",
    "So now you know in ninety-fo who's the shit\n",
    "And who's got the shit dat you just can't fuck wit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to add other regex/cleaning below. In this example I'm just removing the header and email addresses as a demonstration. I went back later and cleaned out a lot of the `[Chorus]`-type notation that's in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n \\n\\nI promise the funk the whole funk and nothin' but the funk...Yoooooohoo\\n\\n I be Da B-R-A-T the new lady wit dat shit ya can't fuck wit (say )\\n\\n\\n\\nUh, fool sittin' all fat brat tat tat tat (bitch and its like that)\\nWell let me lift you to the sky\\nJust climb aboard the B-R-A-T ride\\nThose with no love I stay about like GOD\\nQuick to pull ya trigga nigga quick to pull ya card\\nAnd it don't stop and it don't quit\\nIn ninety-fo I be the sho shot shit\\nAnd in years to come shit ain't gonna change\\nSosodef, you know the name of the game\\nAnd those that say they don't, nigga bitch please\\nCuz, we be known for makin' dem Geeees\\nSettin them swole, steady going gold\\nWhateva we release, whateva we unfold\\nSo now you know in ninety-fo who's the shit\\nAnd who's got the shit dat you just can't fuck wit\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(s):\n",
    "    \"\"\"Cleans string of some fluff\"\"\"\n",
    "    email = re.findall(\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\", s)\n",
    "    header = re.findall('Artist:(?s)(.*)Typed by:', s)\n",
    "\n",
    "    for h in header:\n",
    "        s = s.replace(\"Artist:{}Typed by:\".format(h), \"\")\n",
    "\n",
    "    for e in email:\n",
    "        s = s.replace(e, \"\")\n",
    "        \n",
    "    return s\n",
    "\n",
    "\n",
    "clean(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Scrapin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    schema = \"http://www.ohhla.com/\"\n",
    "    url = schema + url\n",
    "    page = requests.get(url).content\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    table_links = soup.select(\"td > a\")\n",
    "\n",
    "    for link in table_links:\n",
    "        \n",
    "        try:\n",
    "            link = link['href']\n",
    "\n",
    "            if \".txt\" in link:\n",
    "                link = schema + link\n",
    "                lyric_page = requests.get(link).content\n",
    "                lyrics_soup = BeautifulSoup(lyric_page, \"lxml\")\n",
    "                \n",
    "                pre_tag = lyrics_soup.find(\"pre\")\n",
    "                \n",
    "                if pre_tag:\n",
    "                    text = pre_tag.text   \n",
    "                else:\n",
    "                    text = str(lyric_page, 'utf-8')\n",
    "                    \n",
    "                text = clean(text)\n",
    "                with open(\"scraped_lyrics.txt\", \"a\") as f:\n",
    "                    f.write(text)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(link)\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
